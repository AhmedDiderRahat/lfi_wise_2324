{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3ea05ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e15ecf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../lfi-03/images/db/train\\\\cars\\\\1137646735_2fb2752249.jpg',\n",
       " '../lfi-03/images/db/train\\\\cars\\\\2539497709_756f025f62.jpg',\n",
       " '../lfi-03/images/db/train\\\\cars\\\\2847324790_6dd07ffb54.jpg',\n",
       " '../lfi-03/images/db/train\\\\cars\\\\car001.jpg',\n",
       " '../lfi-03/images/db/train\\\\cars\\\\car002.jpg',\n",
       " '../lfi-03/images/db/train\\\\cars\\\\car003.jpg',\n",
       " '../lfi-03/images/db/train\\\\faces\\\\3573927657_df093bae27.jpg',\n",
       " '../lfi-03/images/db/train\\\\faces\\\\3775982780_d5ea306ce6.jpg',\n",
       " '../lfi-03/images/db/train\\\\faces\\\\397642272_cedf622248_z.jpg',\n",
       " '../lfi-03/images/db/train\\\\faces\\\\61060671.jpg',\n",
       " '../lfi-03/images/db/train\\\\faces\\\\face.jpg',\n",
       " '../lfi-03/images/db/train\\\\faces\\\\face2.jpg',\n",
       " '../lfi-03/images/db/train\\\\faces\\\\images.jpg',\n",
       " '../lfi-03/images/db/train\\\\faces\\\\img_1577_crazy-face.jpg',\n",
       " '../lfi-03/images/db/train\\\\flowers\\\\0106476_1.jpg',\n",
       " '../lfi-03/images/db/train\\\\flowers\\\\2682530432_e470494b40.jpg',\n",
       " '../lfi-03/images/db/train\\\\flowers\\\\3826419553_c00dc0e91c.jpg',\n",
       " '../lfi-03/images/db/train\\\\flowers\\\\ANBL.jpg',\n",
       " '../lfi-03/images/db/train\\\\flowers\\\\astra04.jpg',\n",
       " '../lfi-03/images/db/train\\\\flowers\\\\marcinki.jpg']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "images_train = glob.glob('../lfi-03/images/db/train/*/*.jpg')\n",
    "images_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8550b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keypoints(w, h):\n",
    "    keypoints = []\n",
    "    keypointSize = 21\n",
    "    # please sample the image uniformly in a grid\n",
    "    # find the keypoint size and number of sample points\n",
    "    # as hyperparameters\n",
    "\n",
    "    keypoints = [cv2.KeyPoint(i, j, keypointSize) for i in range(h) for j in range(w)]\n",
    "    \n",
    "    return keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47e01900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Implement a SIFT feature extraction for a set of training images ./images/db/train/** (see 2.3 image retrieval)\n",
    "# use ~15x15 keypoints on each image with subwindow of 21px (diameter)\n",
    "\n",
    "def sift_feature_extraction(images):\n",
    "    \n",
    "    # 2. create keypoints on a regular grid (cv2.KeyPoint(r, c, keypointSize), as keypoint size use e.g. 11)\n",
    "    descriptors = []\n",
    "    keypoints = create_keypoints(15, 15)\n",
    "    \n",
    "    labels = []\n",
    "\n",
    "    # 3. use the keypoints for each image and compute SIFT descriptors\n",
    "    #    for each keypoint. this compute one descriptor for each image.\n",
    "\n",
    "    for image in images:\n",
    "        \n",
    "        img_type = image.split('\\\\')[1]\n",
    "        labels.append(img_type)\n",
    "        \n",
    "        # read the images\n",
    "        image = cv2.imread(image)\n",
    "\n",
    "        if image.shape != (15, 15):\n",
    "            #print(f'not shaped: {image.shape}')\n",
    "            image = cv2.resize(image, (int(15), int(15)))   \n",
    "\n",
    "        # convert to gray scale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # sift transformation\n",
    "        sift = cv2.SIFT_create()\n",
    "        kp, descriptor = sift.compute(gray, keypoints)\n",
    "\n",
    "        # add the descriptor in the decriptors\n",
    "        descriptors.append(descriptor.flatten())\n",
    "        \n",
    "    return descriptors, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35c6ba75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 28800)\n",
      "[2 2 2 2 2 2 1 1 1 1 1 1 1 1 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# 2. each descriptor (set of features) need to be flattened in one vector\n",
    "# That means you need a X_train matrix containing a shape of (num_train_images, num_keypoints*num_entry_per_keypoint)\n",
    "# num_entry_per_keypoint = histogram orientations as talked about in class\n",
    "# You also need a y_train vector containing the labels encoded as integers\n",
    "\n",
    "training_data = sift_feature_extraction(images_train)\n",
    "\n",
    "x_train = training_data[0]\n",
    "x_train = np.stack(x_train, axis = 0)\n",
    "print(x_train.shape)\n",
    "\n",
    "train_lables = training_data[1]\n",
    "\n",
    "# Create a dictionary to map labels to integers\n",
    "label_mapping = {label: index for index, label in enumerate(set(train_lables))}\n",
    "\n",
    "y_trains = np.array([label_mapping[x] for x in train_lables])\n",
    "\n",
    "print(y_trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fbeefac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 28800) (4, 28800) 16 4\n"
     ]
    }
   ],
   "source": [
    "# Initialize StratifiedShuffleSplit with the desired test_size\n",
    "stratified_splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=201)\n",
    "\n",
    "# Create indices for the train and validation sets using the splitter\n",
    "train_indices, val_indices = next(stratified_splitter.split(x_train, y_trains))\n",
    "\n",
    "# Create the training and validation sets\n",
    "X_train, X_val = x_train[train_indices], x_train[val_indices]\n",
    "y_train, y_val = y_trains[train_indices], y_trains[val_indices]\n",
    "\n",
    "print(X_train.shape, X_val.shape, len(y_train), len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c2155f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: linear, Validation Accuracy: 75.00%\n",
      "Kernel: poly, Validation Accuracy: 75.00%\n",
      "Kernel: rbf, Validation Accuracy: 100.00%\n",
      "Kernel: sigmoid, Validation Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "# Define a list of kernel options to test\n",
    "kernel_options = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "for kernel in kernel_options:\n",
    "    # Create SVM classifier with the specified kernel\n",
    "    clf = svm.SVC(kernel=kernel)\n",
    "\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the validation set\n",
    "    y_pred = clf.predict(X_val)\n",
    "\n",
    "    # Evaluate the performance\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    print(f\"Kernel: {kernel}, Validation Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3e34745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 0]\n",
      "{'flowers': 0, 'faces': 1, 'cars': 2}\n",
      "(4, 28800) (4,)\n"
     ]
    }
   ],
   "source": [
    "# make the test data\n",
    "\n",
    "test_path = glob.glob('../lfi-03/images/db/test/*.jpg')\n",
    "\n",
    "test_info = sift_feature_extraction(test_path)\n",
    "\n",
    "test_labels = test_info[1]\n",
    "\n",
    "test_labels = [x.replace('.jpg', '') for x in test_labels]\n",
    "\n",
    "for label in test_labels:\n",
    "    if label == 'car':\n",
    "        test_labels[test_labels.index(label)] = 'cars'\n",
    "    elif label == 'face':\n",
    "        test_labels[test_labels.index(label)] = 'faces'\n",
    "    else:\n",
    "        test_labels[test_labels.index(label)] = 'flowers'\n",
    "\n",
    "y_test = np.array([label_mapping[x] for x in test_labels])\n",
    "\n",
    "print(y_test)\n",
    "print(label_mapping)\n",
    "\n",
    "X_test = test_info[0]\n",
    "X_test = np.stack(X_test, axis = 0)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c2a7bb",
   "metadata": {},
   "source": [
    "### Apply Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0badb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Values: [2 1 0 0]\n",
      "Original test data: [2 1 0 0]\n",
      "Final Accuracy: 100.0 %\n",
      "Mapped Class name: {'flowers': 0, 'faces': 1, 'cars': 2}\n"
     ]
    }
   ],
   "source": [
    "# Create SVM classifier with the linear kernel\n",
    "clf = svm.SVC(kernel = 'rbf')\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(x_train, y_trains)\n",
    "\n",
    "# predic the SVM on test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(f'Predicted Values: {y_pred}')\n",
    "print(f'Original test data: {y_test}')\n",
    "\n",
    "# Evaluate the performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Final Accuracy: {accuracy * 100} %')\n",
    "\n",
    "print(f'Mapped Class name: {label_mapping}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bb4098-a633-443e-bc7c-10d98e3584db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
